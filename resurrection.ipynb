{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resurrection.ipynb",
      "provenance": [],
      "mount_file_id": "1xSYfyNWGYcU4zZMCGq9jTIl6UDpvvsxf",
      "authorship_tag": "ABX9TyNmyoUaz2Cn2uv50dFpDfQC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/undefinedzack/stock-market-prediction-using-sentiment-analysis/blob/master/resurrection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibB1nLd1xOj8"
      },
      "source": [
        "# Data Manipulation\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Preprocessing the input data\n",
        "\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Creating ngrams and vectorizing the data\n",
        "\n",
        "from gensim.models import Word2Vec, Phrases\n",
        "from gensim.models.phrases import Phraser\n",
        "\n",
        "# Tools for building a model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, Bidirectional\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySqhQdxIzT5L",
        "outputId": "294e6840-8585-4aed-9764-715092df98db"
      },
      "source": [
        "%cd drive/MyDrive/Colab_Data/\n",
        "\n",
        "%ls -l"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/Colab_Data/'\n",
            "/content/drive/MyDrive/Colab_Data\n",
            "total 410952\n",
            "-rw------- 1 root root   2586020 Feb 20 13:52 200features_10minwords\n",
            "-rw------- 1 root root 407958406 Feb 19 10:33 causeSheDidItThisWay.csv\n",
            "-rw------- 1 root root    479968 Feb 20 13:09 stock_data.csv\n",
            "-rw------- 1 root root   7076794 Feb 16 13:29 stockerbot-export1.csv\n",
            "-rw------- 1 root root   1752624 Feb 16 13:31 tweet_sentiment.csv\n",
            "-rw------- 1 root root    959890 Feb 20 13:28 tweets_labelled.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvDjOBSlziJ3"
      },
      "source": [
        "# creating dataframe\n",
        "\n",
        "# df = pd.read_csv('stock_data.csv')\n",
        "# df = pd.read_csv('stockerbot-export1.csv')\n",
        "\n",
        "df = pd.read_csv('tweet_sentiment.csv')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ARK47MoopMz6",
        "outputId": "13091215-fdf1-48e4-e8c6-18c16b9c9ed3"
      },
      "source": [
        "df.head()\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_tweets</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>video offic mind busi david solomon tell gs in...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>price lumber lb f sinc hit ytd high maci turna...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>say american dream dead</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>barri silbert extrem optimist bitcoin predict ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>satellit avoid attack space junk circl earth paid</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      cleaned_tweets  sentiment\n",
              "0  video offic mind busi david solomon tell gs in...          0\n",
              "1  price lumber lb f sinc hit ytd high maci turna...          0\n",
              "2                            say american dream dead         -1\n",
              "3  barri silbert extrem optimist bitcoin predict ...          1\n",
              "4  satellit avoid attack space junk circl earth paid         -1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNa369XdkFBC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "4ef51420-8ee4-4649-8d12-1a348dc9c34f"
      },
      "source": [
        "sentiments = []\n",
        "for i in df['Sentiment']:\n",
        "  if i==-1:\n",
        "    sentiments.append(0)\n",
        "  else:\n",
        "    sentiments.append(1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Sentiment'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a870c4be98cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msentiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Sentiment'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NEllqjH29uN"
      },
      "source": [
        "# Setup for Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmlYIueb4ldh"
      },
      "source": [
        "non_letters = '[^A-Za-z\\s]'"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XGl5ocK0MCH"
      },
      "source": [
        "def clean(tweet :str) -> str:\n",
        "  \n",
        "  # removing HTML\n",
        "  text = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "\n",
        "  # remove non-letters\n",
        "  letters_only = re.sub(non_letters, \" \", text)\n",
        "\n",
        "  # converting to lower-case\n",
        "  lowercase_letters = letters_only.lower()\n",
        "\n",
        "  return lowercase_letters"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUsaJW9kCovR",
        "outputId": "bd3c93f0-2da1-4ddc-bc53-12a53ee292c8"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\")) \n",
        "\n",
        "def lemmatize(tokens :list) -> list:\n",
        "  \n",
        "  # lemmatize\n",
        "  lemmatized_tokens = list(map(lemmatizer.lemmatize, tokens))\n",
        "\n",
        "  # remove stop words\n",
        "  # meaningful_words = list(filter(lambda x : x not in stop_words, lemmatized_tokens))\n",
        "\n",
        "  return lemmatized_tokens\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz4hDPNhDd-r"
      },
      "source": [
        "def preprocess(tweet :str) -> list:\n",
        "\n",
        "  # clean tweet\n",
        "  clean_tweet = clean(tweet)\n",
        "\n",
        "  # tokenize\n",
        "  tokens = word_tokenize(clean_tweet)\n",
        "\n",
        "  # lemmatize\n",
        "  lemmaz = lemmatize(tokens)\n",
        "\n",
        "  return lemmaz"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYw_110dIAS3"
      },
      "source": [
        "# Data Cleaning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1TDm6tVoih9",
        "outputId": "83a62877-915e-4af9-ab59-59303b9820a1"
      },
      "source": [
        "df['cleaned_tweets'].head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    video offic mind busi david solomon tell gs in...\n",
              "1    price lumber lb f sinc hit ytd high maci turna...\n",
              "2                              say american dream dead\n",
              "3    barri silbert extrem optimist bitcoin predict ...\n",
              "4    satellit avoid attack space junk circl earth paid\n",
              "Name: cleaned_tweets, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owVP8y6lHRJq",
        "outputId": "0490d682-2889-432f-a477-a4b6ea04a3e8"
      },
      "source": [
        "tweets = np.array(df['cleaned_tweets'].astype(str))\n",
        "\n",
        "cleaned_data = np.array(list(map(lambda x : preprocess(x), tweets )))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbXbbRF-KvPL",
        "outputId": "0a7fbd1e-bbb5-48fc-ab2d-a9bc08d35e3f"
      },
      "source": [
        "# bigrams\n",
        "\n",
        "%%time\n",
        "bigrams = Phrases(sentences=cleaned_data)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 387 ms, sys: 2.89 ms, total: 390 ms\n",
            "Wall time: 391 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLZrutTpLJRH",
        "outputId": "539f1b40-8c4b-4219-f452-26c82eddf73f"
      },
      "source": [
        "# trigrams\n",
        "\n",
        "%%time\n",
        "trigrams = Phrases(sentences=bigrams[cleaned_data])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.27 s, sys: 6.17 ms, total: 1.28 s\n",
            "Wall time: 1.29 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8ecxb-gM00D",
        "outputId": "c175e4a6-aa2f-4856-f4e7-678b48233da0"
      },
      "source": [
        "# creating trigram model\n",
        "\n",
        "%%time\n",
        "embedding_vector_size = 256\n",
        "trigrams_model = Word2Vec(\n",
        "    sentences = trigrams[bigrams[cleaned_data]],\n",
        "    size = embedding_vector_size,\n",
        "    min_count=3, window=5, workers=4)\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 15.8 s, sys: 14.6 ms, total: 15.9 s\n",
            "Wall time: 13.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOyI4ETzNOuj",
        "outputId": "e72bda98-4d37-47a5-b125-5da12f79f01d"
      },
      "source": [
        "print(\"Vocabulary size:\", len(trigrams_model.wv.vocab))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 10679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB1Mm3i8NUhS",
        "outputId": "7518f9e1-59ad-4283-fb14-983ff575c31c"
      },
      "source": [
        "trigrams_model.wv.most_similar('crypto')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('first', 0.9999532103538513),\n",
              " ('two', 0.9999401569366455),\n",
              " ('complet', 0.9999380111694336),\n",
              " ('start', 0.9999365210533142),\n",
              " ('plan', 0.9999344348907471),\n",
              " ('want', 0.9999339580535889),\n",
              " ('cbio', 0.999933123588562),\n",
              " ('fdx', 0.9999327063560486),\n",
              " ('order', 0.9999290704727173),\n",
              " ('run', 0.9999281167984009)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXlD84HGNU-F",
        "outputId": "8deecb97-9ed9-42f6-ea17-b7fa0752c237"
      },
      "source": [
        "def vectorize_data(data, vocab: dict) -> list:\n",
        "    print('Vectorize sentences...', end='\\r')\n",
        "    keys = list(vocab.keys())\n",
        "    filter_unknown = lambda word: vocab.get(word, None) is not None\n",
        "    encode = lambda review: list(map(keys.index, filter(filter_unknown, review)))\n",
        "    vectorized = list(map(encode, data))\n",
        "    print('Vectorize sentences... (done)')\n",
        "    return vectorized\n",
        "\n",
        "print('Convert sentences to sentences with ngrams...', end='\\r')\n",
        "X_data = trigrams[bigrams[cleaned_data]]\n",
        "print('Convert sentences to sentences with ngrams... (done)')\n",
        "input_length = 150\n",
        "X_pad = pad_sequences(\n",
        "    sequences=vectorize_data(X_data, vocab=trigrams_model.wv.vocab),\n",
        "    maxlen=input_length,\n",
        "    padding='post')\n",
        "print('Transform sentences to sequences... (done)')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Convert sentences to sentences with ngrams...\rConvert sentences to sentences with ngrams... (done)\n",
            "Vectorize sentences...\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Vectorize sentences... (done)\n",
            "Transform sentences to sequences... (done)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "CAUVjR_4pIh1",
        "outputId": "4b3cc9b9-1747-4d9e-f98a-6ceee9cb1731"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_tweets</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>video offic mind busi david solomon tell gs in...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>price lumber lb f sinc hit ytd high maci turna...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>say american dream dead</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>barri silbert extrem optimist bitcoin predict ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>satellit avoid attack space junk circl earth paid</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      cleaned_tweets  sentiment\n",
              "0  video offic mind busi david solomon tell gs in...          0\n",
              "1  price lumber lb f sinc hit ytd high maci turna...          0\n",
              "2                            say american dream dead         -1\n",
              "3  barri silbert extrem optimist bitcoin predict ...          1\n",
              "4  satellit avoid attack space junk circl earth paid         -1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHGt8gkoPLTb"
      },
      "source": [
        "sentiments = df['sentiment']\n",
        "# sentiments = np.array(sentiments)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_pad,\n",
        "    sentiments,\n",
        "    test_size=0.05,\n",
        "    shuffle=True,\n",
        "    random_state=42)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlxNZ3xAPnYn",
        "outputId": "1a3a5c4d-0592-41d8-a6ef-f0ed07f8cee7"
      },
      "source": [
        "def build_model(embedding_matrix: np.ndarray, input_length: int):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(\n",
        "        input_dim = embedding_matrix.shape[0],\n",
        "        output_dim = embedding_matrix.shape[1], \n",
        "        input_length = input_length,\n",
        "        weights = [embedding_matrix],\n",
        "        trainable=True))\n",
        "    model.add(Bidirectional(LSTM(128, recurrent_dropout=0.1)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "model = build_model(\n",
        "    embedding_matrix=trigrams_model.wv.vectors,\n",
        "    input_length=input_length)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 150, 256)          2733824   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,144,577\n",
            "Trainable params: 3,144,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3owqiIiPsjp",
        "outputId": "2a8dac23-378a-42cc-8748-6935f84b8d75"
      },
      "source": [
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=100,\n",
        "    epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "271/271 [==============================] - 209s 759ms/step - loss: -1.7537 - accuracy: 0.6530 - val_loss: -67.2787 - val_accuracy: 0.8073\n",
            "Epoch 2/5\n",
            "271/271 [==============================] - 206s 762ms/step - loss: -155.8632 - accuracy: 0.8121 - val_loss: -588.2764 - val_accuracy: 0.8530\n",
            "Epoch 3/5\n",
            "271/271 [==============================] - 207s 762ms/step - loss: -780.2181 - accuracy: 0.8528 - val_loss: -1561.0983 - val_accuracy: 0.8579\n",
            "Epoch 4/5\n",
            "271/271 [==============================] - 207s 762ms/step - loss: -1971.3699 - accuracy: 0.8611 - val_loss: -2892.5613 - val_accuracy: 0.8685\n",
            "Epoch 5/5\n",
            "222/271 [=======================>......] - ETA: 37s - loss: -3364.7966 - accuracy: 0.8685"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}